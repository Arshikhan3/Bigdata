Session 1: How to Solve the Big Data Problem
Assignment 1

Ques 1. VARIOUS SOURCES OF BIGDATA

1.Archives : archives of scanned documents,statements,medical record,paper archives etc.
2.Business apps : Project Management, google docs, Marketing automation, expense management etc.
3.Social media : Twitter, Facebook, Youtube, LinkedIn, Blog, Yammer, Instagram, Google+ etc.
4.Docs : XLS, PDF, email, HTML, Word, PPt etc.
5.Media : Images, Audio, Video, Flash Live Streams etc.
6.Data Storage : Sql, NoSql, Hadoop, File Systems etc.
7.Machine Log Data : Event logs, Server data, call detail records, application logs, audit logs etc.
8.Sensor Data : Medical devices, car sensors, Satellites, Traffic recording devices, video games, refrigerators etc.
9.Public Web : Government, Weather, health care services, Census, Wikipedia, IMDB and other web services.

Ques 2. 3 V's OF BIGDATA

1.Volume : Volume refers to the amount of data. Velocity is the measure of how fast the data is coming in. 
For example - Facebook has to handle a tsunami of photographs every day. It has to ingest it all, process it, file it, and somehow, later, 
be able to retrieve it.

2.Variety : Variety refers to the number of types of data.Data can be stored in multiple format. 
For example database,excel, csv, access or for the matter of the fact, it can be stored in a simple text file.
Sometimes the data is not even in the traditional format as we assume, it may be in the form of video, SMS, pdf or something we might
have not thought about it. It is the need of the organization to arrange it and make it meaningful. It will be easy to different
do so if we have data in the same format, however it is not the case most of the time. The real world have data in many formats and
that is the challenge we need to overcome with the Big Data. This variety of the data represent Bigdata.

3.Velocity : Velocity refers to the speed of data processing. The data growth and social media explosion have changed how we look at the
data. There was a time when we used to believe that data of yesterday is recent. The matter of the fact newspapers is still following that
logic. However, news channels and radios have changed how fast we receive the news. Today, people reply on social media to update them with
the latest happening. On social media sometimes a few seconds old messages (a tweet, status updates etc.) is not something interests users.
They often discard old messages and pay attention to recent updates. The data movement is now almost real time and the update window
has reduced to fractions of the seconds. This high velocity data represent Big Data.

Ques 3. HORIZANTAL SCALING AND VERTICAL SCALING 

Horizontal scaling means that you scale by adding more machines into your pool of resources whereas Vertical scaling means that you scale
by adding more power (CPU, RAM) to an existing machine.

Horizontal scalability is the ability to increase capacity by connecting multiple hardware or software entities so that they work as a 
single logical unit.
When servers are clustered, the original server is being scaled out horizontally. If a cluster requires more resources to improve 
performance and provide high availability (HA), an administrator can scale out by adding more servers to the cluster.
An important advantage of horizontal scalability is that it can provide administrators with the ability to increase capacity on the 
fly. Another advantage is that in theory, horizontal scalability is only limited by how many entities can be connected successfully.
The distributed storage system Cassandra, for example, runs on top of hundreds of commodity nodes spread across different data centers.
Because the commodity hardware is scaled out horizontally, Cassandra is fault tolerant and does not have a single point of failure.

Vertical scalability, on the other hand, increases capacity by adding more resources, such as more memory or an additional CPU, to a
machine. Scaling vertically, which is also called scaling up, usually requires downtime while new resources are being added and has 
limits that are defined by hardware. When Amazon RDS customers need to scale vertically, for example, they can switch from a smaller 
to a bigger machine, but Amazon's largest RDS instance has only 68 GB of memory.

Scaling horizontally has both advantages and disadvantages. For example, adding inexpensive commodity computers to a cluster might seem
to be a cost-effective solution at first glance, but it's important for the administrator to know whether the licensing costs for those
additional servers, the additional operations cost of powering and cooling and the large footprint they will occupy in the data center 
truly makes scaling horizontally a better choice than scaling vertically.

Ques 4. NEED AND WORKING OF HADOOP 

Hadoop is an open source software platform managed by the Apache Software Foundation has proven to be very helpful in storing and 
managing vast amounts of data cheaply and efficiently.
But what exactly is Hadoop, and what makes it so special? 
Basically, it’s a way of storing enormous data sets across distributed clusters of servers and then running “distributed” analysis 
applications in each cluster.Hadoop is changing the perception of handling Big Data especially the unstructured data.
It is designed to be robust, in that your Big Data applications will continue to run even when individual servers — or clusters — fail.
And it’s also designed to be efficient, because it doesn’t require your applications to shuttle huge volumes of data across your network.
It has two main parts –
1. Data processing framework - The data processing framework is the tool used to work with the data itself. By default, this is the 
   Java-based system known as MapReduce.
2. Distributed filesystem for data storage - It is the Hadoop component that holds the actual data. By default, Hadoop uses the 
   cleverly named Hadoop Distributed File System (HDFS), although it can use other file systems as well.
   
Hadoop is not really a database: It stores data and you can pull data out of it, but there are no queries involved – SQL or otherwise. 
Hadoop is more of a data warehousing system – so it needs a system like MapReduce to actually process the data. Using MapReduce instead
of a query gives data seekers a lot of power and flexibility, but also adds a lot of complexity.
